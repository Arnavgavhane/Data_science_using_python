{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e560931e-e594-4ec3-a1c4-7b084ac1e8e1",
   "metadata": {},
   "source": [
    "# Neural Network Basics(perceptron,activation functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbecfd-6430-47aa-abe2-9c1cf0e15aa0",
   "metadata": {},
   "source": [
    "#### what is Neural Network?\n",
    "##### imagine how your brain works \n",
    "- your brain has neurons which pass signals to each other\n",
    "- neural networks are inspired by this\n",
    "- a perceptron is like a single brain cell (neuron)\n",
    "- multiple perceptrons connected together is equal to neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c38af-05d3-41e2-87f6-41f0619fc981",
   "metadata": {},
   "source": [
    "### what is perceptron \n",
    "#### think of a perceptron as \n",
    "- it takes inputs (features)\n",
    "- applies weights to those inputs\n",
    "- adds them together + bias\n",
    "- passes result through an activation function to make decisions\n",
    "#### formula : output = Activation ((input1 * weight1) + (input2 * weight2)+ ...+ bias)\n",
    "\n",
    "#### what  is activation function\n",
    "##### activation decides should the nueron fire (activate) or not \n",
    "- introduces not linearily - helps model complex problems\n",
    "##### common activations functions\n",
    "| name | purpose | range |\n",
    "|------|---------|-------|\n",
    "| Sigmoid | binary outputs(0 and 1) | 0 to 1 |\n",
    "| Tanh | outputs between -1 to 1 | -1 to 1 |\n",
    "|ReLU | keeps positive remove negative | 0 to âˆž|\n",
    "\n",
    "#### perceptron with python example\n",
    "we will build a simple perceptron to solve a logical OR problems\n",
    "| input1 | input2 | output (OR) |\n",
    "|--------|--------|--------------|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bea799f0-2766-47e5-9928-eb85f8bd35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X= np. array([\n",
    "                [0,0],\n",
    "                [0,1],\n",
    "                [1,0],\n",
    "                [1,1]\n",
    "            ])\n",
    "y= np.array([0,1,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38f15400-57b6-48f4-84a6-79466ff73b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize weights and bias\n",
    "weights=np.random.rand(2)\n",
    "# two inputs equal to two weights \n",
    "bias=np.random.rand(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed75a0-5da6-4be7-ac1e-1ed0629488f4",
   "metadata": {},
   "source": [
    "#### sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e17b3471-7f45-48a7-8adb-2730af024ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3d2a3-5772-4b98-ac3b-ea5d3c6b7e7d",
   "metadata": {},
   "source": [
    "#### derivative for learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2c695e1-7b98-4809-80c6-c581e0881929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b5c62-9def-4daf-a112-fc767631abd9",
   "metadata": {},
   "source": [
    "## forward pass and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7be983c6-8246-4631-b55d-9092a96f136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights :[6.82394386 6.82783613]\n",
      "Bias:[-2.93464002]\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "learning_rate=0.1\n",
    "appox=1000 # iterations\n",
    "\n",
    "# training loop \n",
    "for appoc in range (appox):   \n",
    "  for i in range (len(X)):\n",
    "     # weighted sum \n",
    "      z=np.dot(X[i],weights)+bias\n",
    "\n",
    "      # apply activation \n",
    "      output= sigmoid(z)\n",
    "\n",
    "      # Error \n",
    "      error=y[i]-output\n",
    "\n",
    "      weights += learning_rate*error*x[i]\n",
    "      bias+= learning_rate*error \n",
    "# print final weights and bias\n",
    "print(f\"Weights :{weights}\")\n",
    "print(f\"Bias:{bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89792c6-6b1d-472b-baa2-b59046bba265",
   "metadata": {},
   "source": [
    "### test the perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "015b24c9-cebc-45c8-ad2a-3761ff2b0007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [0 0] | predicted : 0 | actual : 0\n",
      "input: [0 1] | predicted : 1 | actual : 1\n",
      "input: [1 0] | predicted : 1 | actual : 1\n",
      "input: [1 1] | predicted : 1 | actual : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_209672\\1932602269.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print (f\"input: {X[i]} | predicted : {round(float(output))} | actual : {y[i]}\")\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    z=np.dot(X[i],weights)+bias\n",
    "    output= sigmoid(z)\n",
    "    print (f\"input: {X[i]} | predicted : {round(float(output))} | actual : {y[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073227f-b256-4a00-bed1-1dca13d0a0b8",
   "metadata": {},
   "source": [
    "## what happened here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad1c07-a077-4a91-a625-4bb8f24125fb",
   "metadata": {},
   "source": [
    "- Perceptron took inputs\n",
    "- Applied weights & bias\n",
    "- Used Sigmoid to decide output\n",
    "- Repeated adjustments (learning) for 1000 iterations\n",
    "- After training, model predicts OR gate correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da960fa9-84df-4b12-b143-610b59a0de11",
   "metadata": {},
   "source": [
    "## Beginner-Friendly Notes\n",
    "- Weights = How important each input is\n",
    "- Bias = Extra adjustments for flexibility\n",
    "- Sigmoid = Smooth output between 0 and 1\n",
    "- Learning rate = Step size for updating weights\n",
    "- Epochs = How many times model learns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17846fa1-a8d2-45f1-95d3-b76be9c3ed33",
   "metadata": {},
   "source": [
    "### Real - World Analogy\n",
    "Imagine learning to throw a ball into a basket\n",
    "\n",
    "- You try, miss,adjust (like updating weights)\n",
    "- keep practicing until you consistently hit the target\n",
    "\n",
    "Perceptron learns similarly - adjusts itself based on errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cb4e4-f595-4bf1-b2b3-6e4c0909a335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
